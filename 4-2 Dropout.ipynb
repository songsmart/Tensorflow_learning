{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0Testing Accuaracy0.917Training Accuracy0.9126\n",
      "Iter1Testing Accuaracy0.93Training Accuracy0.9269091\n",
      "Iter2Testing Accuaracy0.936Training Accuracy0.93652725\n",
      "Iter3Testing Accuaracy0.9407Training Accuracy0.94\n",
      "Iter4Testing Accuaracy0.9444Training Accuracy0.94496363\n",
      "Iter5Testing Accuaracy0.9457Training Accuracy0.94832724\n",
      "Iter6Testing Accuaracy0.9496Training Accuracy0.95289093\n",
      "Iter7Testing Accuaracy0.9491Training Accuracy0.95289093\n",
      "Iter8Testing Accuaracy0.9536Training Accuracy0.9558727\n",
      "Iter9Testing Accuaracy0.9545Training Accuracy0.9593273\n",
      "Iter10Testing Accuaracy0.9561Training Accuracy0.9609636\n",
      "Iter11Testing Accuaracy0.9567Training Accuracy0.96236366\n",
      "Iter12Testing Accuaracy0.9598Training Accuracy0.96314543\n",
      "Iter13Testing Accuaracy0.9586Training Accuracy0.96410906\n",
      "Iter14Testing Accuaracy0.9607Training Accuracy0.9651273\n",
      "Iter15Testing Accuaracy0.9619Training Accuracy0.9665091\n",
      "Iter16Testing Accuaracy0.9615Training Accuracy0.9667636\n",
      "Iter17Testing Accuaracy0.9627Training Accuracy0.96772724\n",
      "Iter18Testing Accuaracy0.9632Training Accuracy0.96876365\n",
      "Iter19Testing Accuaracy0.9643Training Accuracy0.9708727\n",
      "Iter20Testing Accuaracy0.9658Training Accuracy0.97132725\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "#每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#创建一个简单的神经网络\n",
    "W1 = tf.Variable(tf.truncated_normal([784,2000],stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([2000])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x,W1)+b1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob )\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([2000,2000],stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([2000])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,W2)+b2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob )\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([2000,1000],stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([1000])+0.1)\n",
    "L3 = tf.nn.tanh(tf.matmul(L2_drop,W3)+b3)\n",
    "L3_drop = tf.nn.dropout(L3,keep_prob )\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([1000,10],stddev=0.1))\n",
    "b4 = tf.Variable(tf.zeros([10])+0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L3_drop,W4)+b4)\n",
    "                              \n",
    "#二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y , logits = prediction))\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax返回一维张量中最大值\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict = {x:batch_xs,y:batch_ys,keep_prob:0.7})\n",
    "        \n",
    "        test_acc = sess.run(accuracy,feed_dict = {x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy,feed_dict = {x:mnist.train.images,y:mnist.train.labels,keep_prob:1.0})\n",
    "        print(\"Iter\" + str(epoch)+\"Testing Accuaracy\"+str(test_acc)+\"Training Accuracy\"+str(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6tensorflow",
   "language": "python",
   "name": "py3.6tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
