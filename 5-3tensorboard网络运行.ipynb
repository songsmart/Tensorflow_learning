{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0Testing Accuaracy0.8415\n",
      "Iter1Testing Accuaracy0.8938\n",
      "Iter2Testing Accuaracy0.9016\n",
      "Iter3Testing Accuaracy0.9063\n",
      "Iter4Testing Accuaracy0.9087\n",
      "Iter5Testing Accuaracy0.9107\n",
      "Iter6Testing Accuaracy0.9125\n",
      "Iter7Testing Accuaracy0.9131\n",
      "Iter8Testing Accuaracy0.9145\n",
      "Iter9Testing Accuaracy0.9172\n",
      "Iter10Testing Accuaracy0.9169\n",
      "Iter11Testing Accuaracy0.9187\n",
      "Iter12Testing Accuaracy0.9176\n",
      "Iter13Testing Accuaracy0.9183\n",
      "Iter14Testing Accuaracy0.9195\n",
      "Iter15Testing Accuaracy0.9201\n",
      "Iter16Testing Accuaracy0.9205\n",
      "Iter17Testing Accuaracy0.9212\n",
      "Iter18Testing Accuaracy0.9211\n",
      "Iter19Testing Accuaracy0.9222\n",
      "Iter20Testing Accuaracy0.9224\n",
      "Iter21Testing Accuaracy0.9216\n",
      "Iter22Testing Accuaracy0.9228\n",
      "Iter23Testing Accuaracy0.9234\n",
      "Iter24Testing Accuaracy0.9225\n",
      "Iter25Testing Accuaracy0.9234\n",
      "Iter26Testing Accuaracy0.9235\n",
      "Iter27Testing Accuaracy0.9236\n",
      "Iter28Testing Accuaracy0.9233\n",
      "Iter29Testing Accuaracy0.9234\n",
      "Iter30Testing Accuaracy0.9239\n",
      "Iter31Testing Accuaracy0.9247\n",
      "Iter32Testing Accuaracy0.9246\n",
      "Iter33Testing Accuaracy0.9237\n",
      "Iter34Testing Accuaracy0.9237\n",
      "Iter35Testing Accuaracy0.9259\n",
      "Iter36Testing Accuaracy0.924\n",
      "Iter37Testing Accuaracy0.9251\n",
      "Iter38Testing Accuaracy0.9261\n",
      "Iter39Testing Accuaracy0.9257\n",
      "Iter40Testing Accuaracy0.9253\n",
      "Iter41Testing Accuaracy0.9255\n",
      "Iter42Testing Accuaracy0.9259\n",
      "Iter43Testing Accuaracy0.9262\n",
      "Iter44Testing Accuaracy0.9259\n",
      "Iter45Testing Accuaracy0.9276\n",
      "Iter46Testing Accuaracy0.927\n",
      "Iter47Testing Accuaracy0.9263\n",
      "Iter48Testing Accuaracy0.9259\n",
      "Iter49Testing Accuaracy0.9273\n",
      "Iter50Testing Accuaracy0.9273\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "#每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#参数概要\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean',mean)#平均值\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev',stddev)#标准差\n",
    "        tf.summary.scalar('max',tf.reduce_max(var))#最大值\n",
    "        tf.summary.scalar('min',tf.reduce_min(var))#最小值\n",
    "        tf.summary.histogram('histogram',var)#直方图\n",
    "        \n",
    "#命名空间\n",
    "with tf.name_scope('input'):\n",
    "    #定义两个placeholder\n",
    "    x = tf.placeholder(tf.float32,[None,784],name = 'x-input')\n",
    "    y = tf.placeholder(tf.float32,[None,10],name = 'y-input')\n",
    "\n",
    "with tf.name_scope('layer'):\n",
    "    #创建一个简单的神经网络\n",
    "    with tf.name_scope('wights'):\n",
    "        W = tf.Variable(tf.zeros([784,10]),name='W')\n",
    "        variable_summaries(W)\n",
    "    with tf.name_scope('biases'):    \n",
    "        b = tf.Variable(tf.zeros([10]),name='b')\n",
    "        variable_summaries(b)\n",
    "    with tf.name_scope('wx_plus_b'):\n",
    "        wx_plus_b = tf.matmul(x,W) + b\n",
    "    with tf.name_scope('softmax'):\n",
    "        prediction = tf.nn.softmax(wx_plus_b)\n",
    "\n",
    "#二次代价函数\n",
    "with tf.name_scope('loss'):\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y , logits = prediction))\n",
    "    tf.summary.scalar('loss',loss)\n",
    "with tf.name_scope('train'):\n",
    "    #使用梯度下降法\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        #结果存放在一个布尔型列表中\n",
    "        correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax返回一维张量中最大值\n",
    "        #求准确率\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        tf.summary.scalar('accuracy',accuracy)\n",
    "\n",
    "#合并所有的summary\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter('logs/',sess.graph)\n",
    "    for epoch in range(51):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            summary,_=sess.run([merged,train_step],feed_dict = {x:batch_xs,y:batch_ys})\n",
    "        \n",
    "        writer.add_summary(summary,epoch)\n",
    "        acc = sess.run(accuracy,feed_dict = {x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter\" + str(epoch)+\"Testing Accuaracy\"+str(acc))\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2001):\n",
    "    #每个批次100个样本\n",
    "    batch_xs,batch_ys = mnist.train.next_batch(100)\n",
    "    summary,_ = sess.run([merged,train_step],feed_dict = {x:batch_xs,y:batch_ys})\n",
    "    writer.add_summary(summary,i)\n",
    "    if i%500 ==0:\n",
    "        print(sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6tensorflow",
   "language": "python",
   "name": "py3.6tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
